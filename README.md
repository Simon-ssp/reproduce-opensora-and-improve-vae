Recently, multimodal big models have led a huge research trend. Almost all the top tech companies and institutions are working on their own multimodal big models. However, open source trained multimodal big models are currently only available in the OpenSora project. In order to explore what pitfalls, tricks, and training overheads exist in the training of multimodal generative macromodels, this project trains and reproduces the OpenSora project from 0; based on this, we propose an adjustment to the video 3D VAE up- and down-sampling module. The experimental results show that OpenSora under the huge training time-consumption only achieves the preliminary video generation function, and the video effect is poor; the modified VAE mitigates the original mesh effect, but brings about the motion residual shadow.

Translated with DeepL.com (free version)
